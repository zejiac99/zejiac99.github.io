<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0" xmlns:itunes="http://www.itunes.com/dtds/podcast-1.0.dtd" xmlns:googleplay="http://www.google.com/schemas/play-podcasts/1.0"><channel><title><![CDATA[Zejia’s Substack]]></title><description><![CDATA[My personal blog]]></description><link>https://zejiac99.substack.com</link><image><url>https://substackcdn.com/image/fetch/w_256,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb0e684aa-91a2-40b5-aa00-32932b37fa0d_1080x1080.jpeg</url><title>Zejia’s Substack</title><link>https://zejiac99.substack.com</link></image><generator>Substack</generator><lastBuildDate>Sun, 13 Apr 2025 20:40:50 GMT</lastBuildDate><atom:link href="https://zejiac99.substack.com/feed" rel="self" type="application/rss+xml"/><copyright><![CDATA[Zejia]]></copyright><language><![CDATA[en]]></language><webMaster><![CDATA[zejiac99@substack.com]]></webMaster><itunes:owner><itunes:email><![CDATA[zejiac99@substack.com]]></itunes:email><itunes:name><![CDATA[Zejia]]></itunes:name></itunes:owner><itunes:author><![CDATA[Zejia]]></itunes:author><googleplay:owner><![CDATA[zejiac99@substack.com]]></googleplay:owner><googleplay:email><![CDATA[zejiac99@substack.com]]></googleplay:email><googleplay:author><![CDATA[Zejia]]></googleplay:author><item><title><![CDATA[Some Thoughts on Deep Seek]]></title><description><![CDATA[The Five Hundred Billion Dollar Surprise]]></description><link>https://zejiac99.substack.com/p/some-thoughts-on-deep-seek</link><guid isPermaLink="false">https://zejiac99.substack.com/p/some-thoughts-on-deep-seek</guid><dc:creator><![CDATA[Zejia]]></dc:creator><pubDate>Sun, 23 Mar 2025 15:15:57 GMT</pubDate><enclosure url="https://substack-post-media.s3.amazonaws.com/public/images/acc04171-6c20-4e2a-9b16-5d8302428ac9_1024x1792.webp" length="0" type="image/jpeg"/><content:encoded><![CDATA[<h3>The Five Hundred Billion Dollar Surprise</h3><p>On January 27, 2025, five hundred billion dollars vanished in a single trading day. Not through scandal or fraud, but an unassuming announcement from DeepSeek about its newly released R1 model, a move that had changed the dynamics of the artificial intelligence world forever.</p><p>Before this pivotal moment, DeepSeek had operated discreetly yet formidably within High-Flyer, one of China&#8217;s largest quantitative hedge funds. Founded by the visionary Liang Wenfeng, DeepSeek sidestepped Western narratives of existential risk or competition, driven instead by pure, relentless curiosity about AGI.</p><p>This ethos began bearing fruit in November 2023, each new model more impressive than the last. By December 2024, DeepSeek introduced DeepSeek-v3, rivaling established models like Anthropic&#8217;s Claude and OpenAI&#8217;s GPT&#8212;but with astonishing efficiency. Training v3 required only $5 million, eleven times less than comparable Western systems, offering users top-tier performance at <a href="https://medium.com/@gragson.john/openai-vs-deepseek-price-comparison-aa199f049bb8">a tenth of OpenAI's price</a>. Yet v3, remarkable as it was, was merely groundwork for something even greater.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07da90be-ef47-48d1-af12-25ad048e3ff4_1024x542.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07da90be-ef47-48d1-af12-25ad048e3ff4_1024x542.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07da90be-ef47-48d1-af12-25ad048e3ff4_1024x542.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07da90be-ef47-48d1-af12-25ad048e3ff4_1024x542.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07da90be-ef47-48d1-af12-25ad048e3ff4_1024x542.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07da90be-ef47-48d1-af12-25ad048e3ff4_1024x542.jpeg" width="1024" height="542" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/07da90be-ef47-48d1-af12-25ad048e3ff4_1024x542.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:542,&quot;width&quot;:1024,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:&quot;Deepseek price to performance ratio&quot;,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="Deepseek price to performance ratio" title="Deepseek price to performance ratio" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07da90be-ef47-48d1-af12-25ad048e3ff4_1024x542.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07da90be-ef47-48d1-af12-25ad048e3ff4_1024x542.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07da90be-ef47-48d1-af12-25ad048e3ff4_1024x542.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F07da90be-ef47-48d1-af12-25ad048e3ff4_1024x542.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a></figure></div><p>On January 25, 2025, DeepSeek unveiled R1, the first reasoning-specialized AI created outside the U.S. Inheriting v3&#8217;s cost-efficiency, R1 introduced powerful chain-of-thought reasoning capabilities, surpassing previously dominant American models. Overnight, DeepSeek redefined global AI innovation.</p><h3>Two Path to Progress</h3><p>To understand how DeepSeek rose so rapidly, we need to recognize two fundamentally different approaches to technological advancement: <em>scaling</em> versus <em>optimization</em>.</p><ul><li><p><em>Scaling</em> is about doubling down on proven methods, riding the momentum of what already works. The compelling logic behind this approach lies in scaling laws: outputs grow disproportionately when inputs increase, creating powerful incentives to pour more resources into existing frameworks.</p></li><li><p><em>Optimization</em> follows an entirely different philosophy. Rather than hoping scaling continues indefinitely, it begins with first principles&#8212;examining each component and streamlining processes to achieve comparable results with minimal resources. It asks not "How much more can we add?" but "How much can we remove while maintaining performance?"</p></li></ul><p>Consider making a car faster: you could add cylinders to your engine (V4 to V8), pursuing the scaling approach. Alternatively, you could turn to install a turbocharger or improve aerodynamics with a spoiler&#8212;the optimization path.</p><p>The same logic applies to language model development. Most leading AI labs train models by leveraging scaling laws, improving performance through bigger architectures with more parameters and compute. Despite recent signs that scaling's marginal returns are diminishing, major players continue pouring billions into training infrastructure.</p><p>The same logic applies to language model development. Most leading AI labs train models by leveraging scaling laws, improving performance through bigger architectures with more parameters and compute. Despite recent signs that scaling's marginal returns are diminishing, major players continue <a href="https://www.reuters.com/technology/meta-invest-up-65-bln-capital-expenditure-this-year-2025-01-24/">pouring billions into training infrastructure</a>. DeepSeek, facing U.S. chip sanctions that limited access to cutting-edge hardware, walked the optimization path out of necessity. They weren't trying to build the world's best-performing model but rather to achieve comparable capabilities at a fraction of the cost.</p><p>Though often framed as competitors, scaling and optimization actually function as partners in progress, each with a distinct role. Scaling serves as the trailblazer, venturing into uncharted technological territory and defining what "good" looks like. Optimization follows as the mapmaker, charting efficient routes through newly discovered terrain. Though it rarely surpasses the benchmarks set by scaling pioneers, that's not its purpose. Instead, optimization democratizes technology by drastically reducing costs, making capabilities accessible to the wider public.</p><p>When DeepSeek's R1 demonstrated performance matching or exceeding U.S. labs' models at one-eleventh the cost, it represented both approaches working in concert&#8212;scaling had defined what was possible, and optimization had made it accessible.</p><h3>The Reinforcement Learning Revolution</h3><p>R1's remarkable performance stems not from a single breakthrough but from a constellation of optimization techniques&#8212;multi-head latent attention compressing memory usage, multi-token prediction densifying each training step, and mixture of experts activating only necessary parts of the model. But among these innovations, one stands out as particularly transformative: <strong>their approach to reinforcement learning.</strong></p><p>To appreciate this shift, consider how high-quality AI assistants are typically created, following a <a href="https://newsletter.languagemodels.co/i/155812052/recap-how-llms-are-trained">traditional three-step recipe</a>. First comes pre-training, where the model absorbs patterns from vast amounts of internet text, creating a so called "base model". Next is supervised fine-tuning (SFT, making the model useful for following instructions. Finally comes preference tuning, which refines behaviors to align with human values.</p><p>Until recently, this final step overwhelmingly relied on RLHF&#8212;Reinforcement Learning from Human Feedback&#8212;where human evaluators rated outputs to guide improvement. RLHF was instrumental in transforming raw models like GPT-3 into useful assistants like ChatGPT, yielding well-formed, concise responses rather than rambling text. But as models grow increasingly sophisticated, a fundamental limitation emerges: human evaluators struggle to judge responses in domains where the AI may already exceed human expertise.</p><p>This dilemma echoes a pivotal moment in 2016, when Google's AlphaGo faced world champion Lee Sedol. During the match's second game, AlphaGo played what commentators later dubbed <a href="https://www.wired.com/2016/03/two-moves-alphago-lee-sedol-redefined-future/">"move 37"</a>&#8212;a play so unconventional that experts initially thought it was a mistake. Yet this seemingly bizarre move ultimately secured victory. It wasn't taught by humans but discovered through pure reinforcement learning, where the system played millions of games against itself, uncovering strategies beyond human convention.</p><p>The trade-off becomes clear: do we want our AI systems to be the next Einstein, discovering unprecedented solutions, or merely <a href="https://x.com/Thom_Wolf/status/1897630495527104932">"good students"</a> that excel at tasks humans already understand?</p><p>The AI industry has long recognized reinforcement learning's power for certain tasks, yet hesitated to apply it fully to language models for two reasons: language tasks seemed too subjective for automated evaluation, and many worried about developing AI without human oversight. As models rapidly scaled in size, however, they began hitting a performance ceiling described by the Chinchilla Scaling Law&#8212;for optimal performance, a model needs about <a href="https://epoch.ai/blog/chinchilla-scaling-a-replication-attempt">20 tokens of training data</a> for every parameter. With high-quality training data nearly exhausted from the accessible internet, the industry desperately needed a new approach.</p><p>OpenAI first tackled this challenge with its reasoning model o1, which demonstrated a striking new capability: the ability to take time to "think" before answering. Unlike earlier models that generated responses token by token in a single pass, o1 would work through multiple draft solutions to complex problems, especially in domains like mathematics and coding where answers can be objectively verified. Despite speculation about OpenAI using reinforcement learning for o1, the company kept its methods closely guarded. With compute constraints and high-quality reasoning data scarce and expensive, creating a similar model seemed insurmountable to most&#8212;until DeepSeek achieved exactly that with R1, effectively revealing the secret sauce OpenAI had been <a href="https://x.com/markchen90/status/1884303237186216272">hiding</a>.</p><p>Deep Seek&#8217;s breakthrough came in the form of a creative solution. R1's performance depended on generating 600,000 chain-of-thought reasoning examples&#8212;a dataset that would cost tens of millions to create with human annotators. Their solution? <a href="https://newsletter.languagemodels.co/i/155812052/deepseek-r-training-recipe">Developing an interim model</a> specialized in high-quality reasoning, inspired by an earlier experiment called R1-Zero, to generate the bulk of these examples.</p><p>But beyond simply creating more training data, Deep Seek designed an innovative reinforcement learning framework that fundamentally changed how their model approached problem-solving. By introducing <a href="https://arc.net/l/quote/cypdhbpm">dual reward functions</a>&#8212;one optimizing for correctness and another for structured reasoning&#8212;they created an environment where the model began developing its own problem-solving strategies. This led to the emergence of &#8220;<a href="https://arc.net/l/quote/udfwlhhq">aha moments</a>,&#8221; instances where the model spontaneously reevaluated its initial approach when recognizing its initial approach was inadequate.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd2b7d78-62ac-408c-8bd7-e14053bb8a46_1518x912.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd2b7d78-62ac-408c-8bd7-e14053bb8a46_1518x912.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd2b7d78-62ac-408c-8bd7-e14053bb8a46_1518x912.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd2b7d78-62ac-408c-8bd7-e14053bb8a46_1518x912.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd2b7d78-62ac-408c-8bd7-e14053bb8a46_1518x912.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd2b7d78-62ac-408c-8bd7-e14053bb8a46_1518x912.png" width="1456" height="875" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/cd2b7d78-62ac-408c-8bd7-e14053bb8a46_1518x912.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:875,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd2b7d78-62ac-408c-8bd7-e14053bb8a46_1518x912.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd2b7d78-62ac-408c-8bd7-e14053bb8a46_1518x912.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd2b7d78-62ac-408c-8bd7-e14053bb8a46_1518x912.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcd2b7d78-62ac-408c-8bd7-e14053bb8a46_1518x912.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">Deep Seek R1-Zero naturally learns to solve reasoning tasks with more thinking time</figcaption></figure></div><p>With this self-generated reasoning dataset in place, Deep Seek structured its training pipeline in three critical phases. First, a supervised fine-tuning (SFT) phase on a small set of manually curated chain-of-thought examples stabilized the model, preventing erratic early-stage behavior (also called "cold start"). Then, large-scale reinforcement learning optimized both reasoning and general capabilities. Finally, through iterative refinement, R1 reached performance parity with American AI labs. The result was a model that, for the first time outside the U.S., matched industry-leading reasoning AIs while being trained at a fraction of the cost.</p><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed7fd8c3-7654-497c-a8e2-1f2e7930992e_3302x1438.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed7fd8c3-7654-497c-a8e2-1f2e7930992e_3302x1438.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed7fd8c3-7654-497c-a8e2-1f2e7930992e_3302x1438.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed7fd8c3-7654-497c-a8e2-1f2e7930992e_3302x1438.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed7fd8c3-7654-497c-a8e2-1f2e7930992e_3302x1438.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed7fd8c3-7654-497c-a8e2-1f2e7930992e_3302x1438.png" width="1456" height="634" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/ed7fd8c3-7654-497c-a8e2-1f2e7930992e_3302x1438.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:634,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:null,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:null,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed7fd8c3-7654-497c-a8e2-1f2e7930992e_3302x1438.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed7fd8c3-7654-497c-a8e2-1f2e7930992e_3302x1438.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed7fd8c3-7654-497c-a8e2-1f2e7930992e_3302x1438.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fed7fd8c3-7654-497c-a8e2-1f2e7930992e_3302x1438.png 1456w" sizes="100vw" loading="lazy"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption">source: <a href="https://newsletter.languagemodels.co/p/the-illustrated-deepseek-r1">The Illustrated DeepSeek-R1</a></figcaption></figure></div><p>More than just an engineering milestone, DeepSeek's success revealed a new paradigm in AI development&#8212;one that, rather than explicitly teaching models how to solve problems, simply provides the right incentives and lets solutions emerge organically.</p><h3>Lessons Beyond Technology</h3><p>DeepSeek's journey offers lessons that transcend the technology itself. First is the wisdom of embracing what we cannot control. When denied cutting-edge chips, they didn't waste energy fighting policy&#8212;they redirected focus to areas within their influence. This mirrors life's fundamental truth: our power lies not in controlling circumstances but in choosing our response. Adaptability begins with acceptance, allowing us to channel energy toward productive paths rather than immovable obstacles.</p><p>The second lesson reveals the strength in finding your path within constraints. DeepSeek didn't try to outspend resource-rich competitors; they redefined the game entirely. This <a href="https://studentsuccess.arizona.edu/increasing-resilience">"realistic optimism"</a> acknowledges limitations while maintaining ambition. Their constraints weren't obstacles but signposts directing them toward their unique contribution. When we stop measuring ourselves against others' advantages and instead leverage our distinctive strengths, we often discover overlooked opportunities for impact.</p><p>Most counterintuitively, DeepSeek demonstrates that discomfort often catalyzes innovation. Their resource limitations didn't hinder progress&#8212;they accelerated it. Forced to question fundamental assumptions, their engineers discovered approaches that abundance might never have revealed.</p><p>These lessons converge on a simple truth: the next breakthrough often waits just beyond our comfort zone, in the fertile space where limitation meets imagination. Perhaps the greatest innovation isn't a new technology at all, but rather our evolving relationship with constraint itself&#8212;seeing it not as our enemy, but as our guide.</p>]]></content:encoded></item><item><title><![CDATA[Approaching Consulting from a Bayesian Lens]]></title><description><![CDATA[Bayes theorem quantifies and systematizes the idea of changing beliefs. So what can we learn from it when it comes to doing our day-to-day jobs?]]></description><link>https://zejiac99.substack.com/p/approaching-consulting-from-a-bayesian</link><guid isPermaLink="false">https://zejiac99.substack.com/p/approaching-consulting-from-a-bayesian</guid><dc:creator><![CDATA[Zejia]]></dc:creator><pubDate>Mon, 11 Sep 2023 14:30:16 GMT</pubDate><enclosure url="https://substack-post-media.s3.amazonaws.com/public/images/dad04c43-ce27-43d7-9522-a14096f3050f_1024x1792.webp" length="0" type="image/jpeg"/><content:encoded><![CDATA[<h2>Bayes theorem quantifies and systematizes the idea of changing beliefs</h2><p>What fascinates me about Bayes' theorem is its ability to succinctly quantify and generalize how we learn, understand, and accept the world in just one equation.</p><p>Richard Price made the following analogy to illustrate the essence of Bayes' theorem when he first introduced the theorem to the world, after discovering it upon Thomas Bayes's death.</p><p>Imagine a primitive caveman emerging from his cave to witness the sunrise for the first time in his existence. Gazing upon the blazing celestial orb, casting luminous lays and emanating scorching heat, he is flabbergasted. The stark contrast to the stygian cave he once lived overwhelms his senses. Yet, as the sun slowly sinks below the horizon, the man quickly sinks into deep thought. "Will this radiant spectacle be repeated tomorrow, in the ensuing week, and every forthcoming day?" he ponders. Although there is no way for him to validate his conjecture and ascertain the sun&#8217;s return, with each successive sunrise, the man becomes a little bit more confident than the day before. Over time, having borne witness to a myriad of sunrises, the man&#8217;s belief becomes inexorably stronger, and he starts to be convinced that this is the nature of the world.</p><p>And that is basically what Bayes' theorem captures - the man's osmosis of the world as he watches the sunrise each day, or more broadly, <em>how will our hypothesis/prior knowledge change given the emergence of new evidence</em>.</p><div class="latex-rendered" data-attrs="{&quot;persistentExpression&quot;:&quot;P(H\\vert E)=\\frac{P(E\\vert H)\\times P(H)}{P(E\\vert H)\\times P(H) + P(E\\vert \\neg H)\\times P(\\neg H)}=\\frac{P(E\\vert H)\\times P(H)}{P(E)}&quot;,&quot;id&quot;:&quot;YMCEINLMQC&quot;}" data-component-name="LatexBlockToDOM"></div><p>The mathematical representation of Bayes' theorem is actually quite straightforward if we strip away the math symbol. What we want to accomplish with the theorem is to find out the posterior, the probability that your hypothesis holds true given the appearance of new evidence. Then to compute the posterior (<code>P(H|E)</code>), we would need three additional inputs:</p><ol><li><p>Prior - <code>P(H)</code> - This is the hypothesis about the probability of an event occurring before you are given any additional evidence</p></li><li><p>When new evidence emerges (<code>P(E)</code>), the probability of it happening can be broken down into two pieces:</p><ol><li><p>Sensitivity of the evidence - <code>P(E|H)</code> - how sensitive the evidence is to the accuracy of your hypothesis</p></li><li><p>The false positive rate - <code>P(E|&#172;H)</code> - how likely it is that the evidence is due to some confounding factor and not specifically to your hypothesis</p></li></ol></li></ol><p>(3Blue1Brown, a YouTube channel that specializes in teaching math in simple and digestible terms, has a <a href="https://youtu.be/HZGCoVF3YvM">video</a> that better explains Bayes&#8217; theorem visually.)</p><p>While the fundamentals of Bayes&#8217; theorem have been widely applied to solve STEM-related problems, I have not seen it get the exposure that it deserves in the realm of strategy consulting.</p><p>Hence, in this article, I will explore how the theorem can revolutionize the way we approach business problem-solving, and will delve into the key lessons that the theorem imparts and unveil its practical implications within the consulting industry. Hopefully, by the end of this article, you will have gained a fresh view of problem-solving, armed with a powerful mental model that can guide you through complex decision-making processes.</p><h2>What we can learn from Bayes' theorem in business problem-solving</h2><p>If you are familiar with management consulting or have ever done any casing, then you probably know that a hypothesis-driven mindset is highly valued in most consulting/strategy-related vocations. The ability to formulate your hypothesis as well as test its validity by analyzing data/evidence from various sources are skills which professional consultants spend their lives honing.</p><p>And guess what...it just so happens that these two capabilities are also the cornerstone of Bayes' Theorem. So, how does its underlying principle provide insight into solving business problems? Here are a few of my thoughts.</p><h3>Having a prior matters, but it is even more important to keep updating it</h3><p>The prior is often the hardest part of Bayes' theorem to figure out. First, not everything has a prior, and sometimes calculating it is no better than flipping a coin. Second, and most importantly, the prior is completely subjective; different people have different priors based on their previous understanding and experience with the problem, which can end up with different answers.</p><p>In fact, in the world of statistics, the prior is categorized as so-called "subjective probability" because of its use as a depiction of a state of belief or knowledge rather than randomness. And there is a real push in academia to get the prior out of the statistics, which later leads to the formation of a new school of thought called the frequentist.</p><p>While the subjective nature of the prior may drive statisticians nuts, it is inextricably linked to the business world where reality is far more complex than a simple equation. Solving business problems is often more art than science, so having robust and relevant priors actually matters a lot in the sense that it helps us to cut through the noise more quickly and efficiently. For experienced professionals who have a strong prior, it will take them substantially fewer iterations or pieces of evidence to arrive at a solution than for novices who may formulate their hypothesis based only on intuition. This is why we see experts with specific domain knowledge/experience becoming coveted targets for companies because of their highly valuable priors, which effectively limit the search space and reduce the number of evidence needed to reach a cogent conclusion.</p><p>That being said, priors only matter to a certain extent. In fact, from a Bayesian perspective, the discrepancy in priors between an expert and a neophyte doesn't really matter. Remember, Bayes' theorem doesn't tell us how to set our prior beliefs. We really shouldn't be debating our prior beliefs, but rather looking at how the new evidence changes them. Since we often deal with only a piece of the problem at the beginning, we won&#8217;t know the entirety perfectly. All we can do is to update our understanding and continue to test our prior as we delve deeper into the problem. Of course, we would never be completely sure of the answer, but the hope is that with each new piece of evidence, we would get closer and closer to the optimal answer, regardless of what priors one has to begin with.</p><h3>Look at both sides of the coin - be careful when evaluating evidence</h3><p>From Bayes' theorem, we know that the denominator (<code>P(E)</code>) can be broken down into two components - the sensitivity (<code>P(E|H)</code>) and the false positive rate (<code>P(E|&#172;H)</code>) of the evidence. There is a clear distinction between the two parameters in that we are looking at two separate spaces here - one with only cases where the hypothesis is true (<code>P(H)</code>) and the other examining the opposite (<code>P(&#172;H)</code>). This is why the ratio of events in these two spaces plays a huge role in determining the posterior. Let's look at an illustrative example to see how all of these play out.</p><p>Suppose that we are the owner of a large grocery store chain, and our objective is to integrate online delivery services into our existing establishments. The idea is that the delivery service can potentially augment sales by attracting a broader customer base, but we are also curious about the profitability of such an investment. Currently, when we open a store in any given location, there is a 30% chance of yielding profitability. Looking at the current market landscape, 70% of the profitable stores support delivery, whereas a mere 25% of the unprofitable stores have invested in this capability. With a 70% chance of being profitable, adding delivery to the business sounds like a no-brainer, right? Well, it is more nuanced than that. Let's use Bayes' theorem to look at the true probability that the store will end up profitable given the added service.</p><div class="latex-rendered" data-attrs="{&quot;persistentExpression&quot;:&quot;P(\\text{profit}\\vert \\text{delivery})=\\frac{P(\\text{delivery}\\vert \\text{profit})\\times P(\\text{profit})}{P(\\text{delivery}\\vert \\text{profit})\\times P(\\text{profit}) + P(\\text{delivery}\\vert \\neg \\text{ profit})\\times P(\\neg \\text{ profit})}&quot;,&quot;id&quot;:&quot;MKAHXJGERQ&quot;}" data-component-name="LatexBlockToDOM"></div><div class="latex-rendered" data-attrs="{&quot;persistentExpression&quot;:&quot;=\\frac{0.7 \\times 0.3}{0.7\\times 0.3 + 0.25\\times 0.7}\\approx 0.55&quot;,&quot;id&quot;:&quot;XFGYUDYPTY&quot;}" data-component-name="LatexBlockToDOM"></div><p>While adding a delivery service may increase the odds of profitability, it doesn't guarantee success. The ratio of profitable stores to unprofitable stores is still relatively low, and there are still unprofitable stores even with the added service. Therefore, the probability of a store becoming profitable with the delivery service is not as high as initially expected. Nevertheless, the addition of the delivery service increases the odds in favor of a profitable store, updating the chance of stores reaching profitability to 55%, which is substantially higher than our 30% prior.</p><p>Bayes&#8217; theorem underscores the complementary nature of the two facets of evidence, akin to the two sides of a coin, working together to offer a holistic picture of the underlying truth. However, when it comes to solving problems in real life, we have this tendency to fixate solely on the sensitivity side of the coin, as in what percentage of instances does the evidence support a hypothesis <em>given</em> that the hypothesis holds true. Such a blind spot may not be obvious, or might even be counterintuitive at first. Yet, if we can embrace the theorem as a mental model, we can better systematically evaluate the incoming evidence and avoid jumping to conclusions based on potentially skewed information.</p><h2>Final Words</h2><p>This is a little bit about the foundational principles of Bayes' theorem and its relevance in the context of work of day-to-day business engagement. In my view, statistics offers a rigorous and unbiased lens through which we can decode the intricacies of our world, though often sheathed in complex mathematical language. This post, in which I explain the theorem with a business twist, is my attempt to translate statistics into relatable lessons. </p><p>More importantly, what truly excites me is the exercise of forging connections between knowledge drawn from disparate domains. It allows me to perceive the familiar world we inhabit from a fresh vantage point and teaches me to be curious, flexible, and open-minded for today, tomorrow, and every day that follows.</p>]]></content:encoded></item><item><title><![CDATA[Will AI Lead To Mass Unemployment]]></title><description><![CDATA[Navigating the Complex Future of Human-AI Interaction at work]]></description><link>https://zejiac99.substack.com/p/will-ai-lead-to-mass-unemployment</link><guid isPermaLink="false">https://zejiac99.substack.com/p/will-ai-lead-to-mass-unemployment</guid><dc:creator><![CDATA[Zejia]]></dc:creator><pubDate>Mon, 14 Aug 2023 02:50:15 GMT</pubDate><enclosure url="https://substack-post-media.s3.amazonaws.com/public/images/58185259-89cf-4da3-9a52-2422d07841f5_1024x1792.webp" length="0" type="image/jpeg"/><content:encoded><![CDATA[<h3>Human beings are by nature quite insecure...</h3><p>If the age of hunting and gathering taught humans anything at that time, it was probably to be ever vigilant and prepared for the unexpected. The peace of mind one has today is not guaranteed tomorrow, as any sense of contentment can get us killed when trying to survive in a precarious environment with unpredictable dangers lurking around every corner.</p><p>In order to stay relevant and manage to survive in the challenging world, we started to invent measures to minimize the uncertainties that we could encounter. We learned how to use fire as a solution to the insecurity of inclement weather and animal attacks; we began grazing in response to the unstable food supply caused by hunting; we initiated large-scale agriculture so that we wouldn't have to rely on luck to gather nutrients that supplement our diets.</p><p>The urgency and the agency to either adapt or address any uncertainty that could threaten our survival became a leitmotif throughout the rest of human civilization. It drove us to evolve and innovate for a better life, leading to great inventions such as electricity, the internal combustion engine, etc. </p><p>Despite the tremendous progress we have made in managing our inner insecurity, our attitude toward it has soured in recent days. The same insecurity that once prods us to adapt and continue to raise our standard of living seems to have become one of the main justifications we default to resist change. We are fraught when confronted with innovation and iconoclastic ideas, even some of which are our own creations, lest the "new thing" might disrupt the reality on which we depend to survive. For examples,</p><ul><li><p>In the Industrial Revolution, <a href="https://en.wikipedia.org/wiki/Luddite">workers went on strike</a> against the introduction of new labor-saving machines</p></li><li><p>In the 1980s, math teachers <a href="https://www.washingtonpost.com/archive/local/1986/04/04/math-teachers-stage-a-calculated-protest/c003ddaf-b86f-4f2b-92ca-08533f3a5896/">protested over the use of calculators</a> in elementary schools</p></li></ul><div class="captioned-image-container"><figure><a class="image-link image2 is-viewable-img" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc4bba4e-1c54-4590-9160-1bb059b4a39e_1170x1362.jpeg" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc4bba4e-1c54-4590-9160-1bb059b4a39e_1170x1362.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc4bba4e-1c54-4590-9160-1bb059b4a39e_1170x1362.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc4bba4e-1c54-4590-9160-1bb059b4a39e_1170x1362.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc4bba4e-1c54-4590-9160-1bb059b4a39e_1170x1362.jpeg 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc4bba4e-1c54-4590-9160-1bb059b4a39e_1170x1362.jpeg" width="536" height="623.9589743589744" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/bc4bba4e-1c54-4590-9160-1bb059b4a39e_1170x1362.jpeg&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:1362,&quot;width&quot;:1170,&quot;resizeWidth&quot;:536,&quot;bytes&quot;:179203,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:false,&quot;topImage&quot;:true,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc4bba4e-1c54-4590-9160-1bb059b4a39e_1170x1362.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc4bba4e-1c54-4590-9160-1bb059b4a39e_1170x1362.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc4bba4e-1c54-4590-9160-1bb059b4a39e_1170x1362.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc4bba4e-1c54-4590-9160-1bb059b4a39e_1170x1362.jpeg 1456w" sizes="100vw" fetchpriority="high"></picture><div class="image-link-expand"><div class="pencraft pc-display-flex pc-gap-8 pc-reset"><div class="pencraft pc-reset icon-container restack-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-refresh-cw"><path d="M3 12a9 9 0 0 1 9-9 9.75 9.75 0 0 1 6.74 2.74L21 8"></path><path d="M21 3v5h-5"></path><path d="M21 12a9 9 0 0 1-9 9 9.75 9.75 0 0 1-6.74-2.74L3 16"></path><path d="M8 16H3v5"></path></svg></div><div class="pencraft pc-reset icon-container view-image"><svg xmlns="http://www.w3.org/2000/svg" width="20" height="20" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="lucide lucide-maximize2"><polyline points="15 3 21 3 21 9"></polyline><polyline points="9 21 3 21 3 15"></polyline><line x1="21" x2="14" y1="3" y2="10"></line><line x1="3" x2="10" y1="21" y2="14"></line></svg></div></div></div></div></a><figcaption class="image-caption"><a href="https://www.linkedin.com/posts/dpjmcgregor_1988-protest-over-use-of-calculators-in-activity-7043256854004588544-bvo_/#fromHistory">source</a></figcaption></figure></div><p>Ironically, while many of us are convinced that each technology leap often <a href="https://gwipp.gwu.edu/sites/g/files/zaxdzs2181/f/downloads/Reamer_The_Impacts_of_Invention_on_Economic_Growth_02-28-14.pdf">ushers in a secular trend of economic and productivity growth</a>, we just cannot help but think of the dystopian scenario where we all get displaced by some new automation technology.</p><p>Having recently been in awe of what AI-powered applications like ChatGPT are capable of doing, our inner sense of insecurity, quite self-evidently, starts to creep in again. Unlike the previous industrial innovations where blue-collar workers were the main victims, the rise of AI technology is seen as a major threat toward knowledge workers who tend to be the well-educated middle class.</p><p>Such fear is further fueled by media reports worrying that the technology is so powerful that it will eventually take over most of the jobs that are currently done by humans, leading to massive disruption of the workforce. Goldman Sachs' recent report about the impact of AI on economic growth predicts that <a href="https://www.key4biz.it/wp-content/uploads/2023/03/Global-Economics-Analyst_-The-Potentially-Large-Effects-of-Artificial-Intelligence-on-Economic-Growth-Briggs_Kodnani.pdf">two-thirds of occupations could be partially replaced by AI</a>, with administrative, legal, architecture, and engineering jobs most likely to be automated.</p><p>While it is certainly true that the advent of AI will create a paradigm shift in how we work and what we do, I don't necessarily buy into the idea that it will make us obsolete. For one thing, there are still many hurdles that AI must overcome before it can truly cement itself as an omnipotent agent. More importantly, we have valued human input and interaction for so long that it seems very unlikely to me that the human-centered world will be upended overnight by AI. So rather than being pessimistic about AI cannibalizing our work, I think it will become an incredible complement to humans - saving us time, turbocharging our productivity, and freeing us up to focus on the very human things that we have always excelled at.</p><div><hr></div><h3>AI, specifically LLM, is a versatile general-purpose agent, with drawbacks to overcome</h3><p>If you have ever played with ChatGPT, an interface of GPT3.5 (a Large Language Model (LLM) model that specializes in natural language processing), you have probably been amazed by the human-like responses it generates. Given an input prompt, it produces such logical and coherent prose that makes you wonder if all those years of education were a waste of time.</p><p>Yes, I get it. It is quite disconcerting to see LLMs performing most natural language tasks such as summarization, translation, answering factual questions, etc. on par with, if not better than, humans, but we shouldn't get too carried away and jump to the conclusion that this ostensibly almighty creation is destined to collapse the human society either.</p><p>My argument stems mostly from the fact that generative AI like LLMs hasn't reached a level of maturity that allows it to completely overthrow humans in the decision-making process, and a lot of the reason has to do with its foundational architecture (i.e., how it is trained to produce seemingly sentient outputs).</p><p>Despite ChatGPT's black magic-like abilities, how it works to produce under the hood is quite simple - <em><a href="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/">it iteratively makes an educated guess as to what the next most contextually appropriate word will be, given the text it has already generated</a></em> - this is also called next token prediction.</p><div class="captioned-image-container"><figure><a class="image-link image2" target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80c15aa5-9f51-4687-bee2-3c1a9799c31f_490x159.png" data-component-name="Image2ToDOM"><div class="image2-inset"><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80c15aa5-9f51-4687-bee2-3c1a9799c31f_490x159.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80c15aa5-9f51-4687-bee2-3c1a9799c31f_490x159.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80c15aa5-9f51-4687-bee2-3c1a9799c31f_490x159.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80c15aa5-9f51-4687-bee2-3c1a9799c31f_490x159.png 1456w" sizes="100vw"><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80c15aa5-9f51-4687-bee2-3c1a9799c31f_490x159.png" width="490" height="159" data-attrs="{&quot;src&quot;:&quot;https://substack-post-media.s3.amazonaws.com/public/images/80c15aa5-9f51-4687-bee2-3c1a9799c31f_490x159.png&quot;,&quot;srcNoWatermark&quot;:null,&quot;fullscreen&quot;:null,&quot;imageSize&quot;:null,&quot;height&quot;:159,&quot;width&quot;:490,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:15211,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null,&quot;belowTheFold&quot;:true,&quot;topImage&quot;:false,&quot;internalRedirect&quot;:null,&quot;isProcessing&quot;:false}" class="sizing-normal" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80c15aa5-9f51-4687-bee2-3c1a9799c31f_490x159.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80c15aa5-9f51-4687-bee2-3c1a9799c31f_490x159.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80c15aa5-9f51-4687-bee2-3c1a9799c31f_490x159.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F80c15aa5-9f51-4687-bee2-3c1a9799c31f_490x159.png 1456w" sizes="100vw" loading="lazy"></picture><div></div></div></a><figcaption class="image-caption"><em><a href="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/#:~:text=It%E2%80%99s%20Just%20Adding%20One%20Word%20at%20a%20Time">It&#8217;s Just Adding One Word at a Time</a></em><a href="https://writings.stephenwolfram.com/2023/02/what-is-chatgpt-doing-and-why-does-it-work/#:~:text=It%E2%80%99s%20Just%20Adding%20One%20Word%20at%20a%20Time">...</a></figcaption></figure></div><p>It is able to make an informed decision about the likelihood of the next words by virtually training on top of the entire Internet, learning billions of pages of human-written text, finding all instances of text with similar context, and then extrapolating which relevant word will come next.</p><p>Such revolutionary architecture is the backbone of LLM's superior performance, enabling it to have a longer memory for processing text as well as a better ability to reason. This, however, does not mean that AI is ready for large-scale deployment in the real world, as there are major shortcomings that make it less capable than one would expect.</p><ol><li><p>The LLM's knowledge is very generalized and highly compressed, making it prone to hallucination</p></li><li><p>LLMs are still considered a black box, resulting in a terrible interface</p></li></ol><p>Let's take these one at a time.</p><h5>LLM is a reasoning machine but <em>not</em> a knowledge expert</h5><p>Hallucination, the tendency of LLMs to spew out facts that are completely false or nonexistent, is one of the biggest roadblocks standing in the way of it becoming a truly trusted source of information.</p><p>LLMs are only good at making decisions based on the information you give them. So if it is not given enough context about the subject of a request, it will struggle to connect the right dots between all the relevant information. One way to resolve this issue is to feed the model with more context through <a href="https://www.oneusefulthing.org/p/a-guide-to-prompting-ai-for-what">prompting</a>. An example of these techniques is called &#8220;chain of thought&#8221;, which grounds the model in a specific context by providing examples of what you want it to accomplish before you formally make requests.</p><p>Providing additional context, however, is not always a panacea, as there is a bigger problem contingent on hallucination that still needs to be addressed - its lossy, overly generalized, and limited knowledge base.</p><p>Virtually all of the knowledge that a language model possesses comes from the Internet. Despite its expansiveness, we can all agree that the Web contains only a fraction of human intelligence. As a result, LLMs tend to have a tough time providing credible answers to subjects that are generally not available on the Internet, such as <a href="https://www.wsj.com/articles/ai-bot-chatgpt-needs-some-help-with-math-assignments-11675390552?mod=article_inline">mathematics</a> and <a href="https://twitter.com/ylecun/status/1647899325412831235?s=20">natural physics</a> (GPT-4 has made great progress, but other LLMs still have trouble solving math problems).</p><p>Still, it is unlikely that the model could imbibe all the information available on the web both for memory and cost considerations, so it would need to compress the knowledge it gains from the training data to a reasonable size. And now concerns are being raised about whether the compression done by the model could distort the semantic meaning of the original source.</p><p>Ted Chiang, a science fiction writer who is famous for his short story "Story of Your Life," likens the LLM to a <a href="https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web">heavily compressed image</a> that is ostensibly seen as an accurate representation of the original, but the details are mostly distorted when zoomed in.</p><blockquote><p>Think of ChatGPT as a blurry JPEG of all the text on the Web. It retains much of the information on the Web, in the same way that a JPEG retains much of the information of a higher-resolution image, but,&nbsp;if you&#8217;re looking for an exact sequence of bits, you won&#8217;t find it; all you will ever get is an approximation.</p></blockquote><p>The lack of nuance in LLMs' knowledge base may not be a huge problem in and of itself - as long as we are aware of its existence, we can still have discretion on whether to treat it as a credible source. But what makes LLMs special, and potentially dangerous, is their ability to fable with extreme confidence and conviction, which can trick people into believing that they capture 100% of the original source when they do not. And we have begun to see <a href="https://www.washingtonpost.com/media/2023/01/17/cnet-ai-articles-journalism-corrections/">AI-fabricated text surface in the real world</a>, <a href="https://fortune.com/2023/06/23/lawyers-fined-filing-chatgpt-hallucinations-in-court/">negatively impacting the legitimacy of professional services</a>.</p><p>What's more, as more and more AI-generated text appears on the Internet and is used to train the next generation AI, the entire Internet starts to become a fuzzy version of itself and a less desirable source for training new models. With the <a href="https://arxiv.org/pdf/2211.04325.pdf">rapid depletion of high-quality training data</a> and the exponential growth of synthetic data online, we may see the quality of AI-generated text reach an asymptote and even <a href="https://arxiv.org/pdf/2305.17493v2.pdf">begin to degrade</a>.</p><h5>AI is a terrible interface</h5><p>Aside from the propensity to hallucinate, another fundamental problem with LLMs is that we do not yet have a solid grasp of how it actually works internally, despite <a href="https://openai.com/research/language-models-can-explain-neurons-in-language-models">some progress</a> made in explaining the underlying construct of language models. Such limited understanding makes LLM a quasi black box - we have no idea how changes in one part of the input will cause which part of the output to alter.</p><p>For clarification, there are still ways for us to exert control over the intended output. First off, we can tweak parameters on the <a href="https://gpt3demo.com/apps/openai-gpt-3-playground">backend</a>, adjusting settings, like the "temperature" that determines the randomness of the output, to customize the model's sentiment and creativity in producing the output. Setting high-level constraints in prompts also helps tailor the model's response (i.e., it will generate text with different tones depending on the role you want it to act). However, there is a limit to how effective these techniques are, and we typically don't have a uniform expectation for the model's response to any given input.</p><p>Ethan Mollick, a professor at Wharton, did an interesting experiment to test how GPT-4's response would change based on whether it was prompted to act as a <em>genius writer</em> or a <em>great writer</em>, or just a <em>writer</em>. According to <a href="https://twitter.com/emollick/status/1649967090500096002?s=20">his Twitter poll</a>, the effect of adding that extra adjective on the quality of the output seems to be trivial.</p><p>Because of the disconnected feedback loop, we are unable to establish a conceptual model to predict how LLMs would behave given an input, making it a <a href="https://magrawala.substack.com/p/unpredictable-black-boxes-are-terrible">terrible interface</a> to interact with. The lack of transparency and predictability will force users into using trial-and-error, hence creating a steeper learning curve for a layperson to utilize the tool effectively.</p><div><hr></div><h3>Some human-specific qualities will never be replaced by AI</h3><p>That said, with the lighting progress of research on AI, I am confident that the aforementioned drawbacks an agent possessed will eventually be resolved by <a href="https://news.agpt.co/">some next generation models</a>, and the day when AI's intelligence surpasses human counterparts may not be that far off. However, does that mean human workers will be then overtaken by agents completely? My sense is probably no, and the major reason is that humans still maintain one big advantage over AI - the fact that the interaction with and the input from our peers is still a quintessential part of how our society works.</p><h5>Human is a better interface than AI</h5><p>If we were to score how good humans are as interfaces, we would probably end up at the lower end of the spectrum. We&nbsp;too often are short of a conceptual model that can precisely predict how another human will interpret and respond to our natural language. This is why conflict and miscommunication are ubiquitous in our everyday life.</p><p>Nonetheless, our conceptual models of human interaction are often still better (more predictive) than AI black boxes, for two main reasons. First, humans' pre-existing knowledge of the world offers a general framework for establishing common ground. Each person has a unique life journey that shapes his or her distinct views of the world, resulting in today's diverse and rich humanity. But underneath the diversity, there is also another knowledge layer, built off of the shared values of the social apparatus. Based on such a strong prior, we would expect others to act similarly to how we would behave on certain things, which helps to reduce friction and facilitate interaction between people of different demographic and cultural heritages.</p><p>Even if there is a misalignment, unlike AI that goes straight into hallucination mode, back-and-forth interactions, and feedback almost always help us reach a consensus in the end. It is perfectly normal for human collaborators not to have a full grasp of what others are saying at the beginning of a conversation, but we would use various repair strategies, such as asking clarifying questions, speaking ideas out loud, sharing common semantics, etc., to fix ambiguities and clear up misunderstandings. Not to mention that working with people is itself a "context-heavy" art that requires as much "instinct" and "experience" as knowledge of the specific subjects. For instance, few job descriptions would include "stakeholder management" as a must-have requirement, but in reality, it is probably a significant part of many jobs. Such abstract capabilities are nowhere to be found on the Internet, nor can they be learned directly, hence there will remain lots and lots of tasks that human beings can perform better than an agent.</p><h5>Human interaction also serves as a vehicle for emotional support</h5><p>Barring being a necessity for professional success, human interaction plays a critical role in <a href="https://www.apa.org/monitor/2019/05/ce-corner-isolation">improving people's physical and emotional well-being</a>. As a gregarious species, we value relationships and derive energy from spending time together. Think about how often our days are brightened by small human touches through real exchanges, like sincere eye contact, a friendly smile, or a burst of laughter, while how annoying it is to be served by an artificial agent when you call customer support.</p><blockquote><p>"A doctor I know once sneaked a beer to a terminally ill patient, to give him something he could savor in a process otherwise devoid of pleasure.&nbsp;It was an idea that didn&#8217;t appear in any clinical playbook, and that went beyond words&#8212;a simple, human gesture." - <a href="https://www.newyorker.com/magazine/2023/03/06/can-ai-treat-mental-illness">A simple human gesture can make a huge differnce</a></p></blockquote><p>But now, imagine a world where all that human work is replaced by autonomous robots. Would you have as much joy interacting with agents as you once did with humans? Sadly, it seems that we are nevertheless heading down this path with little regret. With the proliferation of the Internet and social media, people, especially teenagers, are more <a href="https://digitalnative.substack.com/i/135140436/more-americans-are-living-alone">socially isolated than ever</a>, contributing to the <a href="https://www.theatlantic.com/newsletters/archive/2022/04/american-teens-">rising number of unhappy individuals</a> and <a href="https://www.researchgate.net/figure/Indicators-of-poor-mental-health-among-US-girls-and-young-women-2001-2018-a_fig1_340234729">suicide rates</a>. What's more concerning is that the use of automation technology like AI may <a href="https://www.newyorker.com/science/annals-of-artificial-intelligence/will-ai-become-the-new-mckinsey">exacerbate the inveterate disparity in our society</a>. Human interaction, which should be universally available to all people, is being monetized as <a href="https://www.understandingai.org/i/116441315/human-interaction-as-a-luxury">a form of luxury</a> as businesses use privileges like concierge or VIP phone lines to court affluent individuals. <a href="https://www.reuters.com/technology/ibm-pause-hiring-plans-replace-7800-jobs-with-ai-bloomberg-news-2023-05-01/">Employers</a>, rushing to jump on the AI bandwagon, have begun planning to rule out existing job functions that could be replaced by AI (very much sounds like a pretext to cut jobs in today's high interest rate environment).</p><p>This is not to say that businesses should resist any form of automation and suddenly turn themselves into a non-profit. Instead, companies, especially those in the direct-to-consumer space such as healthcare and hospitality, should strike a balance between hiring human workers and deploying autonomous technology. Rather than fixating on reducing headcount for the sake of sheer efficiency, they should be mindful of the impact of human interaction on both employee morale internally and customer satisfaction externally.</p><div><hr></div><h3>Envisioning a future where AI coexists with human workers harmoniously</h3><p>So, if workers are not going to be overtaken by AI, how will AI be positioned to benefit humanity in the foreseeable future then? My answer is straightforward - AI will make everyone a better, more productive worker by taking over all the drudgery work that we are neither fond of nor great at doing.</p><p>While the creation of the Internet has made information more accessible than ever before, it has also led to an explosion in the amount of data available today, which comes at the cost of limiting people's ability to focus and think strategically.</p><p>Although the human mind is a salient tool for generating ideas and solving complex problems, it is not designed to store or process massive amounts of data. But with social media, online advertising, and sponsored content all competing for web traffic and users' attention, it has become virtually impossible for the unaided human mind to cut through the noise. As a result, we constantly find ourselves spending the majority of our time manually searching for and processing information, leaving little capacity to actually do the things that we typically excel at - thinking, connecting, and creating. In fact, <a href="https://www.microsoft.com/en-us/worklab/work-trend-index/will-ai-fix-work">a Microsoft work trend survey</a> found that 62% of knowledge workers struggle with spending too much time searching for information, and the vast majority of them complain about not having enough uninterrupted focus time during work, highlighting the excessive information overload we all share nowadays.</p><p>Fortunately, such productivity headaches can be dramatically alleviated with the advent of AI, and in particular, LLM-powered technology. AI is at its best when it copes with incremental tasks that progress by adding one word or sentence at a time. Such tasks, like taking meeting notes, drafting emails, or summarizing research articles, which are typically the least preferred work for humans, are some of the most effective use cases for AI.</p><p>That is why I vehemently believe that AI is a complement, <em>not</em> a replacement, for human work, especially for knowledge workers, who have been touted by the media as the group that is most likely to be disrupted. Instead of directly substituting for human judgment in decision making, I envision AI playing the <a href="https://research.contrary.com/reports/from-notetaking-to-neuralink?head=;;about--;;the--;;author">role of emissary</a> between the knowledge layer and the judgment layer, retrieving and processing the information that is most pertinent to our work (to ensure accuracy and reduce hallucination, we would need to refine its knowledge base with contextual data like Enterprise proprietary materials or personal documents).</p><p>Ultimately, no matter how much foothold the narrative of AI-driven mass unemployment gains, most human talent is here to stay for the foreseeable future. And despite some of the aforementioned drawbacks, AI's unique capabilities will reinvigorate humanity's innate creativity and stagnant productivity, not only embarking on the next stage of technological revolution and economic growth but most importantly allowing us to stay off menial tasks and spend more time interacting with our human companions.</p>]]></content:encoded></item></channel></rss>